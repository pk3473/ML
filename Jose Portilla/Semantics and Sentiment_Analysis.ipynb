{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Topics:\n",
    "    \n",
    "    1. Understanding Semantic Word Vectors\n",
    "    2. Understanding Sentiment Analysis\n",
    "    3. Leverage Sentiment Analysis for Text Classification\n",
    "    \n",
    "https://spacy.io/usage/models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the command line, download the medium or large spacy english models:\n",
    "\n",
    "    > python -m spacy download en_core_web_md\n",
    "    > python -m spacy download en_core_web_lg\n",
    "    \n",
    "\n",
    "If we don't specify _md or _lg, by default it small word vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretrained word vectors\n",
    "\n",
    "    1. Word2Vec\n",
    "        - It is a two-layer neural net that processes text.\n",
    "        - Input = Text Corpus\n",
    "        - Output = Set of Vectors: feature vectors for words in that corpus\n",
    "        - It is useful group the vectors of similar words together in vector space.\n",
    "        - It detects similarities mathematically\n",
    "        - It establishes the word's association with other words (e.g. 'man' is to 'boy' and 'woman' is to 'girl')\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It trains words against the other words that neighbor them in the input corpus. It does in 2 ways.\n",
    "    1. Either using context to prdict a target word ( using CBOW: Continuous Bag of Words method)\n",
    "    2. or Word to predict a target context (Skip-Gram Method)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Recall:\n",
    "    \n",
    "        1. Each word is now represented by a vector\n",
    "        2. In spacy each of these vectors has 300 dimensions    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Vectors with Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Medium is already installed hence successul, install large in anacond prompt using the above command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.8963e-01, -4.0309e-01,  3.5350e-01, -4.7907e-01, -4.3311e-01,\n",
       "        2.3857e-01,  2.6962e-01,  6.4332e-02,  3.0767e-01,  1.3712e+00,\n",
       "       -3.7582e-01, -2.2713e-01, -3.5657e-01, -2.5355e-01,  1.7543e-02,\n",
       "        3.3962e-01,  7.4723e-02,  5.1226e-01, -3.9759e-01,  5.1333e-03,\n",
       "       -3.0929e-01,  4.8911e-02, -1.8610e-01, -4.1702e-01, -8.1639e-01,\n",
       "       -1.6908e-01, -2.6246e-01, -1.5983e-02,  1.2479e-01, -3.7276e-02,\n",
       "       -5.7125e-01, -1.6296e-01,  1.2376e-01, -5.5464e-02,  1.3244e-01,\n",
       "        2.7519e-02,  1.2592e-01, -3.2722e-01, -4.9165e-01, -3.5559e-01,\n",
       "       -3.0630e-01,  6.1185e-02, -1.6932e-01, -6.2405e-02,  6.5763e-01,\n",
       "       -2.7925e-01, -3.0450e-03, -2.2400e-02, -2.8015e-01, -2.1975e-01,\n",
       "       -4.3188e-01,  3.9864e-02, -2.2102e-01, -4.2693e-02,  5.2748e-02,\n",
       "        2.8726e-01,  1.2315e-01, -2.8662e-02,  7.8294e-02,  4.6754e-01,\n",
       "       -2.4589e-01, -1.1064e-01,  7.2250e-02, -9.4980e-02, -2.7548e-01,\n",
       "       -5.4097e-01,  1.2823e-01, -8.2408e-02,  3.1035e-01, -6.3394e-02,\n",
       "       -7.3755e-01, -5.4992e-01,  9.9999e-02, -2.0758e-01, -3.9674e-02,\n",
       "        2.0664e-01, -9.7557e-02, -3.7092e-01,  2.7901e-01, -6.2218e-01,\n",
       "       -1.0280e-01,  2.3271e-01,  4.3838e-01,  3.2445e-02, -2.9866e-01,\n",
       "       -7.3611e-02,  7.1594e-01,  1.4241e-01,  2.7770e-01, -3.9892e-01,\n",
       "        3.6656e-02,  1.5759e-01,  8.2014e-02, -5.7343e-01,  3.5457e-01,\n",
       "        2.2491e-01, -6.2699e-01, -8.8106e-02,  2.4361e-01,  3.8533e-01,\n",
       "       -1.4083e-01,  1.7691e-01,  7.0897e-02,  1.7951e-01, -4.5907e-01,\n",
       "       -8.2120e-01, -2.6631e-02,  6.2549e-02,  4.2415e-01, -8.9630e-02,\n",
       "       -2.4654e-01,  1.4156e-01,  4.0187e-01, -4.1232e-01,  8.4516e-02,\n",
       "       -1.0626e-01,  7.3145e-01,  1.9217e-01,  1.4240e-01,  2.8511e-01,\n",
       "       -2.9454e-01, -2.1948e-01,  9.0460e-01, -1.9098e-01, -1.0340e+00,\n",
       "       -1.5754e-01, -1.1964e-01,  4.9888e-01, -1.0624e+00, -3.2820e-01,\n",
       "       -1.1232e-02, -7.9482e-01,  3.7275e-01, -6.8710e-03, -2.5772e-01,\n",
       "       -4.7005e-01, -4.1387e-01, -6.4089e-02, -2.8033e-01, -4.0778e-02,\n",
       "       -2.4866e+00,  6.2494e-03, -1.0210e-02,  1.2752e-01,  3.4965e-01,\n",
       "       -1.2571e-01,  3.1570e-01,  4.1926e-01,  2.0056e-01, -5.5984e-01,\n",
       "       -2.2801e-01,  1.2012e-01, -2.0518e-03, -8.9764e-02, -8.0373e-02,\n",
       "        1.1969e-02, -2.6978e-01,  3.4829e-01,  7.3664e-03, -1.1137e-01,\n",
       "        6.3410e-01,  3.8449e-01, -6.2248e-01,  4.1145e-02,  2.5922e-01,\n",
       "        6.5811e-01, -4.9548e-01, -1.3030e-01, -3.8279e-01,  1.1156e-01,\n",
       "       -4.3085e-01,  3.4473e-01,  2.7109e-02, -2.5108e-01, -2.8011e-01,\n",
       "        2.1662e-01,  3.2660e-01,  5.5895e-02,  7.6077e-02, -5.2480e-02,\n",
       "        4.5928e-02, -2.5266e-01,  5.2845e-01, -1.3145e-01, -1.2453e-01,\n",
       "        4.0556e-01,  3.1877e-01,  2.4415e-02, -2.2620e-01, -6.1960e-01,\n",
       "       -4.0886e-01, -3.5534e-02, -5.5123e-03,  2.3438e-01,  8.7854e-01,\n",
       "       -2.5161e-01,  4.0600e-01, -4.4284e-01,  3.4934e-01, -5.6429e-01,\n",
       "       -2.3676e-01,  6.2199e-01, -2.8175e-01,  4.2024e-01,  1.0043e-01,\n",
       "       -1.4720e-01,  4.9593e-01, -3.5850e-01, -1.3998e-01, -2.7494e-01,\n",
       "        2.3827e-01,  5.7268e-01,  7.9025e-02,  1.7872e-02, -2.1829e-01,\n",
       "        5.5050e-02, -5.4200e-01,  1.6788e-01,  3.9065e-01,  3.0209e-01,\n",
       "        2.3040e-01, -3.9351e-02, -2.1078e-01, -2.7224e-01,  1.6907e-01,\n",
       "        5.4819e-01,  9.4888e-02,  7.9798e-01, -6.6158e-02,  1.9844e-01,\n",
       "        2.0307e-01,  4.4808e-02, -1.0240e-01, -6.9909e-02, -3.6756e-02,\n",
       "        9.5159e-02, -2.7830e-01, -1.0597e-01, -1.6276e-01, -1.8211e-01,\n",
       "       -3.1897e-01, -2.1633e-01,  1.4994e-01, -7.2057e-02,  2.2264e-01,\n",
       "       -4.5551e-01,  3.0341e-01,  1.8431e-01,  2.1681e-01, -3.1940e-01,\n",
       "        2.6426e-01,  5.8106e-01,  5.4635e-02,  6.3238e-01,  4.3169e-01,\n",
       "        9.0343e-02,  1.9494e-01,  3.5483e-01, -2.0706e-02, -7.3117e-01,\n",
       "        1.2941e-01,  1.7418e-01, -1.5065e-01,  5.3355e-02,  4.4794e-02,\n",
       "       -1.6600e-01,  2.2007e-01, -5.3970e-01, -2.4968e-01, -2.6464e-01,\n",
       "       -5.5515e-01,  5.8242e-01,  2.2295e-01,  2.4433e-01,  4.5275e-01,\n",
       "        3.4693e-01,  1.2255e-01, -3.9059e-02, -3.2749e-01, -2.7891e-01,\n",
       "        1.3766e-01,  3.8392e-01,  1.0543e-03, -1.0242e-02,  4.9205e-01,\n",
       "       -1.7922e-01,  4.1215e-02,  1.3547e-01, -2.0598e-01, -2.3194e-01,\n",
       "       -7.7701e-01, -3.8237e-01, -7.6383e-01,  1.9418e-01, -1.5441e-01,\n",
       "        8.9740e-01,  3.0626e-01,  4.0376e-01,  2.1738e-01, -3.8050e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp(u'lion').vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp(u'lion').vector.shape # It is a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp(u'fox').vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.09217995e-01, -2.78227981e-02, -3.57064009e-02,  1.55218393e-01,\n",
       "       -1.28050027e-02,  1.31627038e-01, -1.99465990e-01,  4.75811996e-02,\n",
       "        1.26798794e-01,  1.64792800e+00, -3.57592016e-01, -1.39875397e-01,\n",
       "       -1.26122087e-02, -2.02728346e-01, -2.25237608e-01,  2.15431936e-02,\n",
       "        7.78958052e-02,  9.29676056e-01, -2.75549982e-02, -3.71005982e-01,\n",
       "       -1.42800003e-01, -3.66641544e-02, -1.07376035e-02, -1.84352830e-01,\n",
       "        2.29006782e-02, -5.17717972e-02, -2.78652012e-01, -1.19738199e-01,\n",
       "        5.10960072e-03, -2.85990000e-01, -1.58261746e-01,  2.96241999e-01,\n",
       "        1.09597601e-01, -4.18331996e-02,  1.87256075e-02, -1.03439607e-01,\n",
       "       -5.10879979e-02, -3.51091917e-03, -6.81461841e-02, -2.05657601e-01,\n",
       "        1.66347414e-01, -9.31599736e-03, -4.61134054e-02, -1.05457589e-01,\n",
       "        2.31313989e-01,  1.80005193e-01, -2.06444815e-01, -1.37050152e-02,\n",
       "        1.70106202e-01, -2.19812002e-02, -2.14003205e-01,  1.07415602e-01,\n",
       "       -2.80592032e-02, -5.23634031e-02, -4.86331955e-02, -1.04047179e-01,\n",
       "        1.27018047e-02,  2.02107817e-01, -1.18217587e-01, -1.51981995e-01,\n",
       "        5.12168184e-02,  5.64177930e-02,  5.44355996e-02,  5.15560023e-02,\n",
       "        5.14240041e-02, -1.37740612e-01, -8.45800620e-03, -1.13289997e-01,\n",
       "        1.34828404e-01, -2.25100014e-02,  1.19754001e-01,  5.12372032e-02,\n",
       "        5.40098026e-02,  7.36430064e-02, -1.59269981e-02, -2.37861007e-01,\n",
       "       -7.90134817e-02, -1.30640596e-01,  4.45272028e-02, -4.98013981e-02,\n",
       "       -7.30358064e-02,  1.80923387e-01,  4.17133979e-02,  4.45965007e-02,\n",
       "        1.77781999e-01,  1.66720040e-02,  6.30389988e-01,  4.30720389e-01,\n",
       "        2.10017413e-01,  1.68576598e-01,  7.29599595e-03,  1.58338398e-01,\n",
       "        3.79000008e-02, -3.46915185e-01,  1.33294016e-01, -9.09054056e-02,\n",
       "       -6.90027997e-02, -5.71460137e-03,  6.47759885e-02, -2.06994608e-01,\n",
       "        1.64740205e-01, -2.13680025e-02, -1.30543396e-01, -3.02743949e-02,\n",
       "       -1.03020016e-02, -6.46848023e-01,  1.80351987e-01, -9.54739973e-02,\n",
       "       -1.40800001e-02, -3.42049934e-02, -4.12111953e-02, -1.11505605e-01,\n",
       "        1.27132609e-01, -1.88302785e-01,  1.13260604e-01,  1.80767015e-01,\n",
       "        6.53811991e-02, -1.58561952e-02,  9.68780071e-02,  7.01044053e-02,\n",
       "        4.83391993e-02, -1.63396388e-01, -4.51015905e-02, -9.61597934e-02,\n",
       "       -3.00761998e-01,  1.63111001e-01,  4.52036038e-02, -7.97460005e-02,\n",
       "       -1.00108802e-01, -5.79720028e-02, -1.80559454e-03, -8.24856013e-02,\n",
       "       -1.32837012e-01,  7.58986026e-02,  1.25125393e-01, -1.17681786e-01,\n",
       "       -2.02512026e-01, -5.02933972e-02, -3.09894979e-02, -1.96231812e-01,\n",
       "       -2.05938005e+00, -1.78128034e-02,  1.31141797e-01,  5.38920052e-02,\n",
       "        2.48921394e-01, -8.28451961e-02,  2.29120012e-02,  4.11577933e-02,\n",
       "        6.28991947e-02,  1.26971409e-01,  3.54279988e-02, -1.65512592e-01,\n",
       "        1.54437393e-01, -8.91011953e-02, -2.38956213e-01,  3.74409966e-02,\n",
       "       -1.47978395e-01,  1.23184405e-01,  7.47255981e-02, -8.21532011e-02,\n",
       "       -3.02814040e-02, -1.99475795e-01, -2.98164397e-01, -5.18049970e-02,\n",
       "       -5.98729961e-02, -1.95260614e-01, -1.14224993e-01, -7.07461983e-02,\n",
       "       -1.35402009e-01, -1.59228414e-01,  1.33558795e-01,  1.44477993e-01,\n",
       "       -2.50075996e-01, -2.07789987e-01, -3.69598001e-01, -1.38345197e-01,\n",
       "        2.83456177e-01, -4.93402767e-04, -2.13945992e-02,  1.83038004e-02,\n",
       "       -3.45086008e-02, -1.53184995e-01, -2.21591994e-01, -1.14851996e-01,\n",
       "        9.88069996e-02,  1.29306391e-01, -5.40879965e-02, -4.65750024e-02,\n",
       "       -4.59119631e-03,  1.25648379e-02,  2.73273796e-01,  3.86317968e-02,\n",
       "        6.49093613e-02,  3.70982066e-02,  1.26923593e-02,  1.85716420e-01,\n",
       "        1.69222593e-01,  1.06119812e-01,  1.43199565e-03, -7.52920061e-02,\n",
       "       -1.51146010e-01,  4.95879985e-02, -2.87192404e-01, -2.74599995e-02,\n",
       "        2.10097998e-01,  1.37594968e-01, -1.26467999e-02, -1.47451401e-01,\n",
       "       -6.98073283e-02,  1.16517963e-02,  7.65941963e-02,  8.24979991e-02,\n",
       "       -3.28646004e-02,  2.22982407e-01,  8.53662044e-02,  1.13203190e-01,\n",
       "       -3.06712002e-01,  6.65521994e-02, -2.42485963e-02,  1.85453802e-01,\n",
       "        6.33899868e-03,  2.36580381e-03, -6.98355958e-02,  9.46911126e-02,\n",
       "       -2.32161760e-01, -1.91601396e-01,  2.09780186e-01,  1.91669196e-01,\n",
       "        2.42458023e-02,  4.20044035e-01, -1.50683997e-02,  4.16760286e-03,\n",
       "       -7.33660609e-02,  5.19229956e-02, -1.21735949e-02, -8.69527981e-02,\n",
       "       -1.26489595e-01, -6.72094822e-02,  1.63832814e-01,  2.75269568e-01,\n",
       "       -1.64249986e-01, -1.52959794e-01, -5.64128049e-02, -9.03348029e-02,\n",
       "        3.59305963e-02, -1.62403792e-01, -9.81536135e-02,  3.03588063e-02,\n",
       "       -2.10355401e-01,  5.90659976e-02, -3.81862000e-02, -1.31029800e-01,\n",
       "       -1.98952004e-01,  1.02112450e-01,  1.69432998e-01,  4.52830084e-02,\n",
       "        2.06268996e-01,  1.30002588e-01,  3.64079997e-02,  1.67501979e-02,\n",
       "        1.52415991e-01,  8.69902000e-02,  1.43315807e-01, -1.03890002e-01,\n",
       "        2.32943982e-01, -2.00447604e-01,  8.02273974e-02, -4.50324044e-02,\n",
       "       -2.33428001e-01,  9.64580029e-02, -8.72388482e-04,  2.65751779e-01,\n",
       "       -4.15487401e-02, -1.38139397e-01, -3.27680036e-02, -4.31547984e-02,\n",
       "        3.97300012e-02,  1.05935797e-01,  9.52792179e-04,  3.66709009e-02,\n",
       "        1.43723994e-01,  9.49178040e-02, -1.12830400e-01,  1.76364794e-01,\n",
       "       -2.80858018e-02, -3.65898088e-02,  7.58539960e-02,  7.08954111e-02,\n",
       "       -7.30042011e-02,  1.27999904e-02, -2.66412795e-01,  1.81497976e-01,\n",
       "       -2.59018000e-02, -1.16812006e-01, -7.90375918e-02,  2.10512038e-02,\n",
       "        2.83426046e-02,  4.26702015e-02, -1.21463798e-01, -1.45020094e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp(u'The quick brown fox jumped').vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = nlp('lion cat pet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lion cat pet"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lion lion 1.0\n",
      "lion cat 0.52654374\n",
      "lion pet 0.39923766\n",
      "cat lion 0.52654374\n",
      "cat cat 1.0\n",
      "cat pet 0.7505456\n",
      "pet lion 0.39923766\n",
      "pet cat 0.7505456\n",
      "pet pet 1.0\n"
     ]
    }
   ],
   "source": [
    "for token1 in tokens:\n",
    "    for token2 in tokens:\n",
    "        print(token1.text,token2.text,token1.similarity(token2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can clearly see the Words Vectors with Similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = nlp('like love hate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "like like 1.0\n",
      "like love 0.65790397\n",
      "like hate 0.6574652\n",
      "love like 0.65790397\n",
      "love love 1.0\n",
      "love hate 0.6393099\n",
      "hate like 0.6574652\n",
      "hate love 0.6393099\n",
      "hate hate 1.0\n"
     ]
    }
   ],
   "source": [
    "for token1 in tokens:\n",
    "    for token2 in tokens:\n",
    "        print(token1.text,token2.text,token1.similarity(token2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar words will have similar vectors with high cosine similarity. In English, love and hate are opposite but if you see it has high similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nlp.vocab.vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "684831"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nlp.vocab.vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It means this has 684831 unique word vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(684831, 300)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.vocab.vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = nlp(u\"dog cat nargle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog True 7.0336733 False\n",
      "cat True 6.6808186 False\n",
      "nargle False 0.0 True\n"
     ]
    }
   ],
   "source": [
    "for token in tokens:\n",
    "    print(token.text,token.has_vector,token.vector_norm,token.is_oov) # vector_norm = normalized vector, is_oov = is out of vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import spatial\n",
    "\n",
    "cosine_similarity = lambda vec1, vec2: 1 - spatial.distance.cosine(vec1,vec2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.<lambda>(vec1, vec2)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "king = nlp.vocab['king'].vector\n",
    "man = nlp.vocab['man'].vector\n",
    "woman = nlp.vocab['woman'].vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# king - man + woman   ---> New Vector similar to Queen, princess, highness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_vector = king-man+woman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "computed_similarities = []\n",
    "\n",
    "# FOR ALL WORDS (684831) IN VOCAB\n",
    "\n",
    "for word in nlp.vocab:\n",
    "    if word.has_vector:\n",
    "        if word.is_lower:\n",
    "            if word.is_alpha:\n",
    "                similarity = cosine_similarity(new_vector,word.vector)\n",
    "                computed_similarities.append((word,similarity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "computed_similarities = sorted(computed_similarities,key = lambda item:-item[1]) # lambda item:-item[1], gives descending order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['king', 'queen', 'prince', 'kings', 'princess', 'royal', 'throne', 'queens', 'monarch', 'kingdom']\n"
     ]
    }
   ],
   "source": [
    "print([t[0].text for t in computed_similarities[:10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['king', 'queen', 'prince', 'kings', 'princess', 'royal', 'throne', 'queens', 'monarch', 'kingdom']\n"
     ]
    }
   ],
   "source": [
    "print([t[0].text for t in computed_similarities[:10]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis\n",
    "\n",
    "** VADER Sentiment with NLTK**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- VADER (Valence Aware Dictionary for SEntiment Reasoning) is a model used for text sentiment analysis that is senstive to both polarity (Positive/Negative) and intensity (strength) of emotion)\n",
    "    \n",
    "- It is available in the NLTK package and can be directly applied to unlabelled text data.\n",
    "    \n",
    "- VADER Sentiment analysis relies on a dictionary which maps lexical features to emotion intensities called sentiment score\n",
    "    \n",
    "- The Sentiment score of a text can be obtained by summing up the intensity of each word in the text. \n",
    "    \n",
    "- Note that every single word has some sort of positive or negative value attached to it\n",
    "    \n",
    "E.g. \n",
    " \n",
    "- words like \"love\", \"like\",\"happy\",\"enjoy\" all convey a positive sentiment\n",
    "- VADER is intelligent enough to understand basic context like \"did not love\" as negative sentiment\n",
    "- It also understands capitalization and punctuation such as \"Love!!!\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentiment Analysis on raw text is always challenging however due to variety of possible factors \n",
    "\n",
    "- Positive and Negative Sentiment in the same text data\n",
    "- Sarcasm using positive words in a negative way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\chalampp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sid = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.0, 'neu': 0.508, 'pos': 0.492, 'compound': 0.4404}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = \"This is a good movie\"\n",
    "\n",
    "sid.polarity_scores(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.0, 'neu': 0.425, 'pos': 0.575, 'compound': 0.8877}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = \"This was the best, most awesome movie EVER MADE!!!\"\n",
    "\n",
    "sid.polarity_scores(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.47, 'neu': 0.53, 'pos': 0.0, 'compound': -0.7964}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = \"This was Worst Movie that has ever disgraced the screen\"\n",
    "\n",
    "sid.polarity_scores(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A compound score above zero indicates some sort of positive score and then a compound score below zero indicates some sort of negative score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reviews Amazon text\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"amazonreviews.tsv\",sep ='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>pos</td>\n",
       "      <td>Stuning even for the non-gamer: This sound tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>pos</td>\n",
       "      <td>The best soundtrack ever to anything.: I'm rea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>pos</td>\n",
       "      <td>Amazing!: This soundtrack is my favorite music...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>pos</td>\n",
       "      <td>Excellent Soundtrack: I truly like this soundt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>pos</td>\n",
       "      <td>Remember, Pull Your Jaw Off The Floor After He...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                             review\n",
       "0   pos  Stuning even for the non-gamer: This sound tra...\n",
       "1   pos  The best soundtrack ever to anything.: I'm rea...\n",
       "2   pos  Amazing!: This soundtrack is my favorite music...\n",
       "3   pos  Excellent Soundtrack: I truly like this soundt...\n",
       "4   pos  Remember, Pull Your Jaw Off The Floor After He..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['pos', 'neg'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.label.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neg    5097\n",
       "pos    4903\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "blanks = []\n",
    "\n",
    "for i,lb,rv in df.itertuples():\n",
    "    # index, label, review\n",
    "    if type(rv) == str:\n",
    "        if rv.isspace():\n",
    "            blanks.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blanks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.drop(blanks,inplace = True) # This is not something clear from video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Stuning even for the non-gamer: This sound track was beautiful! It paints the senery in your mind so well I would recomend it even to people who hate vid. game music! I have played the game Chrono Cross but out of all of the games I have ever played it has the best music! It backs away from crude keyboarding and takes a fresher step with grate guitars and soulful orchestras. It would impress anyone who cares to listen! ^_^'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0]['review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>pos</td>\n",
       "      <td>Stuning even for the non-gamer: This sound tra...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                             review\n",
       "0   pos  Stuning even for the non-gamer: This sound tra..."
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.088, 'neu': 0.669, 'pos': 0.243, 'compound': 0.9454}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sid.polarity_scores(df.iloc[0]['review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['scores'] = df['review'].apply(lambda review:sid.polarity_scores(review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>review</th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>pos</td>\n",
       "      <td>Stuning even for the non-gamer: This sound tra...</td>\n",
       "      <td>{'neg': 0.088, 'neu': 0.669, 'pos': 0.243, 'co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>pos</td>\n",
       "      <td>The best soundtrack ever to anything.: I'm rea...</td>\n",
       "      <td>{'neg': 0.018, 'neu': 0.837, 'pos': 0.145, 'co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>pos</td>\n",
       "      <td>Amazing!: This soundtrack is my favorite music...</td>\n",
       "      <td>{'neg': 0.04, 'neu': 0.692, 'pos': 0.268, 'com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>pos</td>\n",
       "      <td>Excellent Soundtrack: I truly like this soundt...</td>\n",
       "      <td>{'neg': 0.09, 'neu': 0.615, 'pos': 0.295, 'com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>pos</td>\n",
       "      <td>Remember, Pull Your Jaw Off The Floor After He...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.746, 'pos': 0.254, 'comp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                             review  \\\n",
       "0   pos  Stuning even for the non-gamer: This sound tra...   \n",
       "1   pos  The best soundtrack ever to anything.: I'm rea...   \n",
       "2   pos  Amazing!: This soundtrack is my favorite music...   \n",
       "3   pos  Excellent Soundtrack: I truly like this soundt...   \n",
       "4   pos  Remember, Pull Your Jaw Off The Floor After He...   \n",
       "\n",
       "                                              scores  \n",
       "0  {'neg': 0.088, 'neu': 0.669, 'pos': 0.243, 'co...  \n",
       "1  {'neg': 0.018, 'neu': 0.837, 'pos': 0.145, 'co...  \n",
       "2  {'neg': 0.04, 'neu': 0.692, 'pos': 0.268, 'com...  \n",
       "3  {'neg': 0.09, 'neu': 0.615, 'pos': 0.295, 'com...  \n",
       "4  {'neg': 0.0, 'neu': 0.746, 'pos': 0.254, 'comp...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the above syntax to ML Index Preprocessing and put in Github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['compound'] = df['scores'].apply(lambda d:d['compound'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>review</th>\n",
       "      <th>scores</th>\n",
       "      <th>compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>pos</td>\n",
       "      <td>Stuning even for the non-gamer: This sound tra...</td>\n",
       "      <td>{'neg': 0.088, 'neu': 0.669, 'pos': 0.243, 'co...</td>\n",
       "      <td>0.9454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>pos</td>\n",
       "      <td>The best soundtrack ever to anything.: I'm rea...</td>\n",
       "      <td>{'neg': 0.018, 'neu': 0.837, 'pos': 0.145, 'co...</td>\n",
       "      <td>0.8957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>pos</td>\n",
       "      <td>Amazing!: This soundtrack is my favorite music...</td>\n",
       "      <td>{'neg': 0.04, 'neu': 0.692, 'pos': 0.268, 'com...</td>\n",
       "      <td>0.9858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>pos</td>\n",
       "      <td>Excellent Soundtrack: I truly like this soundt...</td>\n",
       "      <td>{'neg': 0.09, 'neu': 0.615, 'pos': 0.295, 'com...</td>\n",
       "      <td>0.9814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>pos</td>\n",
       "      <td>Remember, Pull Your Jaw Off The Floor After He...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.746, 'pos': 0.254, 'comp...</td>\n",
       "      <td>0.9781</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                             review  \\\n",
       "0   pos  Stuning even for the non-gamer: This sound tra...   \n",
       "1   pos  The best soundtrack ever to anything.: I'm rea...   \n",
       "2   pos  Amazing!: This soundtrack is my favorite music...   \n",
       "3   pos  Excellent Soundtrack: I truly like this soundt...   \n",
       "4   pos  Remember, Pull Your Jaw Off The Floor After He...   \n",
       "\n",
       "                                              scores  compound  \n",
       "0  {'neg': 0.088, 'neu': 0.669, 'pos': 0.243, 'co...    0.9454  \n",
       "1  {'neg': 0.018, 'neu': 0.837, 'pos': 0.145, 'co...    0.8957  \n",
       "2  {'neg': 0.04, 'neu': 0.692, 'pos': 0.268, 'com...    0.9858  \n",
       "3  {'neg': 0.09, 'neu': 0.615, 'pos': 0.295, 'com...    0.9814  \n",
       "4  {'neg': 0.0, 'neu': 0.746, 'pos': 0.254, 'comp...    0.9781  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If Compound Score is greater than Zero, it is Positive. Otherwwise it is negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['comp_score'] = df['compound'].apply(lambda score: 'pos' if score >=0 else 'neg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>review</th>\n",
       "      <th>scores</th>\n",
       "      <th>compound</th>\n",
       "      <th>comp_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>pos</td>\n",
       "      <td>Stuning even for the non-gamer: This sound tra...</td>\n",
       "      <td>{'neg': 0.088, 'neu': 0.669, 'pos': 0.243, 'co...</td>\n",
       "      <td>0.9454</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>pos</td>\n",
       "      <td>The best soundtrack ever to anything.: I'm rea...</td>\n",
       "      <td>{'neg': 0.018, 'neu': 0.837, 'pos': 0.145, 'co...</td>\n",
       "      <td>0.8957</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>pos</td>\n",
       "      <td>Amazing!: This soundtrack is my favorite music...</td>\n",
       "      <td>{'neg': 0.04, 'neu': 0.692, 'pos': 0.268, 'com...</td>\n",
       "      <td>0.9858</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>pos</td>\n",
       "      <td>Excellent Soundtrack: I truly like this soundt...</td>\n",
       "      <td>{'neg': 0.09, 'neu': 0.615, 'pos': 0.295, 'com...</td>\n",
       "      <td>0.9814</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>pos</td>\n",
       "      <td>Remember, Pull Your Jaw Off The Floor After He...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.746, 'pos': 0.254, 'comp...</td>\n",
       "      <td>0.9781</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                             review  \\\n",
       "0   pos  Stuning even for the non-gamer: This sound tra...   \n",
       "1   pos  The best soundtrack ever to anything.: I'm rea...   \n",
       "2   pos  Amazing!: This soundtrack is my favorite music...   \n",
       "3   pos  Excellent Soundtrack: I truly like this soundt...   \n",
       "4   pos  Remember, Pull Your Jaw Off The Floor After He...   \n",
       "\n",
       "                                              scores  compound comp_score  \n",
       "0  {'neg': 0.088, 'neu': 0.669, 'pos': 0.243, 'co...    0.9454        pos  \n",
       "1  {'neg': 0.018, 'neu': 0.837, 'pos': 0.145, 'co...    0.8957        pos  \n",
       "2  {'neg': 0.04, 'neu': 0.692, 'pos': 0.268, 'com...    0.9858        pos  \n",
       "3  {'neg': 0.09, 'neu': 0.615, 'pos': 0.295, 'com...    0.9814        pos  \n",
       "4  {'neg': 0.0, 'neu': 0.746, 'pos': 0.254, 'comp...    0.9781        pos  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7091"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(df['label'], df['comp_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.86      0.51      0.64      5097\n",
      "         pos       0.64      0.91      0.75      4903\n",
      "\n",
      "    accuracy                           0.71     10000\n",
      "   macro avg       0.75      0.71      0.70     10000\n",
      "weighted avg       0.75      0.71      0.70     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(df['label'], df['comp_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2623 2474]\n",
      " [ 435 4468]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(df['label'], df['comp_score']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Movie Review Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('moviereviews.tsv',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>neg</td>\n",
       "      <td>how do films like mouse hunt get into theatres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>neg</td>\n",
       "      <td>some talented actresses are blessed with a dem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>pos</td>\n",
       "      <td>this has been an extraordinary year for austra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>pos</td>\n",
       "      <td>according to hollywood movies made in last few...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>neg</td>\n",
       "      <td>my first press screening of 1998 and already i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                             review\n",
       "0   neg  how do films like mouse hunt get into theatres...\n",
       "1   neg  some talented actresses are blessed with a dem...\n",
       "2   pos  this has been an extraordinary year for austra...\n",
       "3   pos  according to hollywood movies made in last few...\n",
       "4   neg  my first press screening of 1998 and already i..."
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "blanks =[]\n",
    "\n",
    "for i,lb,rv in df.itertuples():\n",
    "    # index, label, review\n",
    "    if type(rv) == str:\n",
    "        if rv.isspace():\n",
    "            blanks.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[57, 71, 147, 151, 283, 307, 313, 323, 343, 351, 427, 501, 633, 675, 815, 851, 977, 1079, 1299, 1455, 1493, 1525, 1531, 1763, 1851, 1905, 1993]\n"
     ]
    }
   ],
   "source": [
    "print(blanks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(blanks,inplace= True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[57, 71, 147, 151, 283, 307, 313, 323, 343, 351, 427, 501, 633, 675, 815, 851, 977, 1079, 1299, 1455, 1493, 1525, 1531, 1763, 1851, 1905, 1993]\n"
     ]
    }
   ],
   "source": [
    "print(blanks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pos    969\n",
       "neg    969\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "sid = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['scores'] = df['review'].apply(lambda review: sid.polarity_scores(review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>review</th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>neg</td>\n",
       "      <td>how do films like mouse hunt get into theatres...</td>\n",
       "      <td>{'neg': 0.121, 'neu': 0.778, 'pos': 0.101, 'co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>neg</td>\n",
       "      <td>some talented actresses are blessed with a dem...</td>\n",
       "      <td>{'neg': 0.12, 'neu': 0.775, 'pos': 0.105, 'com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>pos</td>\n",
       "      <td>this has been an extraordinary year for austra...</td>\n",
       "      <td>{'neg': 0.067, 'neu': 0.783, 'pos': 0.15, 'com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>pos</td>\n",
       "      <td>according to hollywood movies made in last few...</td>\n",
       "      <td>{'neg': 0.069, 'neu': 0.786, 'pos': 0.145, 'co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>neg</td>\n",
       "      <td>my first press screening of 1998 and already i...</td>\n",
       "      <td>{'neg': 0.09, 'neu': 0.822, 'pos': 0.088, 'com...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                             review  \\\n",
       "0   neg  how do films like mouse hunt get into theatres...   \n",
       "1   neg  some talented actresses are blessed with a dem...   \n",
       "2   pos  this has been an extraordinary year for austra...   \n",
       "3   pos  according to hollywood movies made in last few...   \n",
       "4   neg  my first press screening of 1998 and already i...   \n",
       "\n",
       "                                              scores  \n",
       "0  {'neg': 0.121, 'neu': 0.778, 'pos': 0.101, 'co...  \n",
       "1  {'neg': 0.12, 'neu': 0.775, 'pos': 0.105, 'com...  \n",
       "2  {'neg': 0.067, 'neu': 0.783, 'pos': 0.15, 'com...  \n",
       "3  {'neg': 0.069, 'neu': 0.786, 'pos': 0.145, 'co...  \n",
       "4  {'neg': 0.09, 'neu': 0.822, 'pos': 0.088, 'com...  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 scores\n",
      "0     {'neg': 0.121, 'neu': 0.778, 'pos': 0.101, 'co...\n",
      "1     {'neg': 0.12, 'neu': 0.775, 'pos': 0.105, 'com...\n",
      "2     {'neg': 0.067, 'neu': 0.783, 'pos': 0.15, 'com...\n",
      "3     {'neg': 0.069, 'neu': 0.786, 'pos': 0.145, 'co...\n",
      "4     {'neg': 0.09, 'neu': 0.822, 'pos': 0.088, 'com...\n",
      "...                                                 ...\n",
      "1995  {'neg': 0.073, 'neu': 0.764, 'pos': 0.163, 'co...\n",
      "1996  {'neg': 0.237, 'neu': 0.689, 'pos': 0.074, 'co...\n",
      "1997  {'neg': 0.15, 'neu': 0.705, 'pos': 0.145, 'com...\n",
      "1998  {'neg': 0.129, 'neu': 0.711, 'pos': 0.16, 'com...\n",
      "1999  {'neg': 0.071, 'neu': 0.741, 'pos': 0.188, 'co...\n",
      "\n",
      "[1938 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df[['scores']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['compound'] = df['scores'].apply(lambda d:d['compound'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['comp_score'] = df['compound'].apply(lambda score: 'pos' if score >=0 else 'neg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>review</th>\n",
       "      <th>scores</th>\n",
       "      <th>compound</th>\n",
       "      <th>comp_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>neg</td>\n",
       "      <td>how do films like mouse hunt get into theatres...</td>\n",
       "      <td>{'neg': 0.121, 'neu': 0.778, 'pos': 0.101, 'co...</td>\n",
       "      <td>-0.9125</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>neg</td>\n",
       "      <td>some talented actresses are blessed with a dem...</td>\n",
       "      <td>{'neg': 0.12, 'neu': 0.775, 'pos': 0.105, 'com...</td>\n",
       "      <td>-0.8618</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>pos</td>\n",
       "      <td>this has been an extraordinary year for austra...</td>\n",
       "      <td>{'neg': 0.067, 'neu': 0.783, 'pos': 0.15, 'com...</td>\n",
       "      <td>0.9953</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>pos</td>\n",
       "      <td>according to hollywood movies made in last few...</td>\n",
       "      <td>{'neg': 0.069, 'neu': 0.786, 'pos': 0.145, 'co...</td>\n",
       "      <td>0.9972</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>neg</td>\n",
       "      <td>my first press screening of 1998 and already i...</td>\n",
       "      <td>{'neg': 0.09, 'neu': 0.822, 'pos': 0.088, 'com...</td>\n",
       "      <td>-0.7264</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                             review  \\\n",
       "0   neg  how do films like mouse hunt get into theatres...   \n",
       "1   neg  some talented actresses are blessed with a dem...   \n",
       "2   pos  this has been an extraordinary year for austra...   \n",
       "3   pos  according to hollywood movies made in last few...   \n",
       "4   neg  my first press screening of 1998 and already i...   \n",
       "\n",
       "                                              scores  compound comp_score  \n",
       "0  {'neg': 0.121, 'neu': 0.778, 'pos': 0.101, 'co...   -0.9125        neg  \n",
       "1  {'neg': 0.12, 'neu': 0.775, 'pos': 0.105, 'com...   -0.8618        neg  \n",
       "2  {'neg': 0.067, 'neu': 0.783, 'pos': 0.15, 'com...    0.9953        pos  \n",
       "3  {'neg': 0.069, 'neu': 0.786, 'pos': 0.145, 'co...    0.9972        pos  \n",
       "4  {'neg': 0.09, 'neu': 0.822, 'pos': 0.088, 'com...   -0.7264        neg  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6367389060887513"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(df['label'], df['comp_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.72      0.44      0.55       969\n",
      "         pos       0.60      0.83      0.70       969\n",
      "\n",
      "    accuracy                           0.64      1938\n",
      "   macro avg       0.66      0.64      0.62      1938\n",
      "weighted avg       0.66      0.64      0.62      1938\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(df['label'], df['comp_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[427 542]\n",
      " [162 807]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(df['label'], df['comp_score']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis Assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Perform Vector Arithmetic on your own words\n",
    "\n",
    "Goal: Come as close to an expected word as possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Spacy and load the large language library\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the words you wish to compare and obtain their vectors\n",
    "\n",
    "word1 = nlp.vocab['wolf'].vector\n",
    "word2 = nlp.vocab['dog'].vector\n",
    "word3 = nlp.vocab['cat'].vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import spatial and define a cosine_similarity function\n",
    "\n",
    "from scipy import spatial\n",
    "\n",
    "cosine_sim = lambda x,y: 1 - spatial.distance.cosine(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write an expression for vector arithmetic\n",
    "# for example, new vector = word1-word2+word3\n",
    "\n",
    "new_vector = word1-word2+word3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.31050038e-01, -7.70348012e-01, -1.61958992e-01,  5.14509976e-02,\n",
       "       -4.39818025e-01,  5.61370015e-01, -7.02800155e-02, -1.59049034e-02,\n",
       "       -3.21312010e-01,  3.47299814e-01, -4.55450028e-01, -8.28244984e-01,\n",
       "       -7.40220010e-01, -5.42928994e-01, -5.63299805e-02,  4.28279996e-01,\n",
       "       -4.62331504e-01,  4.05170023e-01, -5.48449993e-01,  1.02373034e-01,\n",
       "        1.80074990e-01, -7.66499713e-03, -2.12929994e-01, -2.46849999e-01,\n",
       "       -5.52890062e-01,  9.38629806e-02, -7.23510027e-01,  7.02539980e-02,\n",
       "        5.78920245e-02,  1.84492990e-01, -4.80529994e-01,  2.75459979e-02,\n",
       "        6.71660006e-02, -5.13229966e-01,  2.37689972e-01, -3.08634996e-01,\n",
       "        3.63579988e-01, -1.35779977e-01, -7.75561988e-01, -4.09240007e-01,\n",
       "       -3.27869982e-01,  3.85720015e-01,  3.15609947e-02, -1.71799973e-01,\n",
       "        6.24130011e-01,  2.73019969e-02, -2.17069983e-01,  3.58170003e-01,\n",
       "       -6.13200068e-02, -3.95631999e-01, -1.76720008e-01, -1.14570022e-01,\n",
       "       -6.55736983e-01, -9.14748907e-02, -5.13620019e-01, -3.11610043e-01,\n",
       "       -3.33386004e-01,  3.16150010e-01,  3.79950583e-01,  1.39960021e-01,\n",
       "        5.87500446e-03, -1.16848797e-01, -1.95110068e-02, -7.61590004e-01,\n",
       "       -5.90600014e-01, -2.85609990e-01, -1.24830008e-01, -4.09950167e-02,\n",
       "        4.91731107e-01, -4.76163030e-01,  3.83399993e-01, -8.43399987e-02,\n",
       "       -5.26211083e-01, -3.78809988e-01, -3.46466005e-01,  6.23516977e-01,\n",
       "       -4.75839972e-01, -4.99099493e-02,  4.18850005e-01, -3.62799972e-01,\n",
       "       -9.68000293e-03, -1.96059018e-01,  6.59770012e-01,  7.53539979e-01,\n",
       "        6.22070014e-01, -3.21700007e-01,  1.08907986e+00, -7.71560073e-02,\n",
       "        1.96569979e-01,  3.93941015e-01, -1.04179978e-02,  7.58900046e-02,\n",
       "       -2.44010054e-02, -1.05455995e+00,  1.26237988e-01, -4.83850002e-01,\n",
       "        2.39899904e-02,  2.75130004e-01, -8.63810182e-02,  3.70970011e-01,\n",
       "       -1.24909401e-01,  4.26950008e-01,  2.03523993e-01,  3.97080034e-02,\n",
       "       -1.44252986e-01, -9.81040001e-01,  3.71429980e-01, -1.57549009e-01,\n",
       "       -2.65230000e-01,  3.94029975e-01,  1.10208020e-01,  5.74499965e-02,\n",
       "        3.66270006e-01, -1.22520995e+00, -2.87450016e-01,  4.38091964e-01,\n",
       "        1.58252001e-01,  1.85795009e-01,  2.75606990e-01,  4.61439967e-01,\n",
       "       -1.16912007e-01, -5.55723011e-01,  1.08862996e+00, -7.29069948e-01,\n",
       "       -5.31690001e-01,  3.06210011e-01,  2.87169993e-01, -1.76618978e-01,\n",
       "       -9.14950013e-01, -6.37829900e-02, -3.91300172e-02, -5.42359948e-01,\n",
       "       -2.61259019e-01, -1.22139990e-01,  3.08182001e-01,  4.25031006e-01,\n",
       "       -8.61109972e-01, -4.72699970e-01, -1.07039988e-01,  4.15156007e-01,\n",
       "       -2.71810007e+00,  1.75460011e-01, -5.05509019e-01,  1.05009973e-01,\n",
       "        1.40429974e-01,  3.12720001e-01, -2.30310887e-01, -2.29829982e-01,\n",
       "       -1.60552993e-01, -5.70474029e-01, -2.77104080e-01, -5.47700375e-03,\n",
       "        2.16629028e-01,  4.27509993e-02,  8.93410027e-01,  9.67379808e-02,\n",
       "       -6.47546127e-02,  3.27570021e-01,  1.09510005e-01,  1.07298994e+00,\n",
       "        5.32029986e-01, -3.87449980e-01, -9.74184036e-01, -3.34679991e-01,\n",
       "        8.85309950e-02,  8.96609873e-02, -6.89045012e-01, -5.72497010e-01,\n",
       "       -3.77822012e-01, -3.33095998e-01, -2.49231994e-01,  1.66586995e-01,\n",
       "       -1.20750979e-01,  1.99960008e-01, -6.26125395e-01,  5.76830029e-01,\n",
       "        1.06318200e+00, -6.61490083e-01, -2.01179996e-01,  2.20629930e-01,\n",
       "       -2.78321028e-01, -3.21359992e-01,  2.95656979e-01,  1.10089988e-01,\n",
       "       -4.70340043e-01, -1.39389992e-01, -4.52513993e-01, -2.30767980e-01,\n",
       "        1.50028899e-01, -8.57400298e-02,  4.15970087e-02,  2.59624004e-01,\n",
       "       -1.78999990e-01, -2.16020048e-01,  9.22899961e-01,  4.26420003e-01,\n",
       "        6.27239943e-02, -3.91209990e-01, -1.37199759e-02, -1.76046997e-01,\n",
       "       -4.25839990e-01,  6.09243989e-01, -5.50269961e-01, -2.93646991e-01,\n",
       "       -8.47920105e-02, -4.52275991e-01,  1.87230021e-01,  8.47630128e-02,\n",
       "       -4.63569999e-01, -6.40861690e-01,  3.51080000e-01,  1.03940010e-01,\n",
       "        8.49002600e-03,  1.09519988e-01,  2.10587010e-01, -3.27129990e-01,\n",
       "       -3.51738989e-01,  5.38730025e-01,  3.30994993e-01,  2.71548688e-01,\n",
       "       -3.65408003e-01, -2.61699855e-02, -2.02610001e-01, -1.31089985e-01,\n",
       "        4.99400049e-02,  3.97200018e-01,  9.10300016e-01,  7.39619970e-01,\n",
       "        8.41400102e-02,  1.08899109e-01, -2.39800006e-01, -9.28249881e-02,\n",
       "       -2.20200017e-01, -2.35240996e-01,  7.21499771e-02, -1.22207999e-01,\n",
       "       -6.20449007e-01, -4.70023990e-01,  2.80089974e-02, -3.16390038e-01,\n",
       "       -3.59710008e-01,  4.49225187e-01,  2.15335995e-01, -6.56260028e-02,\n",
       "       -4.66200113e-02, -1.94677308e-01,  5.63167989e-01,  6.62439942e-01,\n",
       "        3.26789975e-01, -7.79739022e-01, -3.10249984e-01, -2.62999982e-01,\n",
       "       -9.76800025e-02,  1.03044009e+00,  2.18171373e-01, -3.18778008e-01,\n",
       "       -6.08583987e-01,  2.95673013e-01,  9.06334817e-02, -6.51859999e-01,\n",
       "       -4.64065999e-01,  1.15209013e-01,  3.95361006e-01,  1.20670021e-01,\n",
       "        4.57944989e-01, -4.84549999e-01,  3.30794990e-01, -3.67448986e-01,\n",
       "        1.15570992e-01, -2.32865989e-01, -5.05580068e-01, -2.40004063e-03,\n",
       "        1.42717987e-01, -2.00480998e-01,  1.47107989e-01, -9.05800313e-02,\n",
       "        2.27445006e-01,  9.95599926e-02, -2.45819986e-01, -4.04026002e-01,\n",
       "        2.63533980e-01,  5.58099985e-01,  6.30230010e-02, -7.24699974e-01,\n",
       "        4.35009986e-01,  3.23070019e-01,  5.10860085e-02, -4.24060017e-01,\n",
       "       -1.81750000e-01, -1.49455011e-01, -6.88588023e-01,  3.60010028e-01,\n",
       "       -1.63883999e-01,  3.60495508e-01, -1.17083997e-01,  7.76620030e-01,\n",
       "       -3.66622001e-01,  4.96960014e-01, -2.14143008e-01, -5.52599013e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the top ten closest vectors in the vocabulary to the result of the\n",
    "\n",
    "computed_sims = []\n",
    "\n",
    "for word in nlp.vocab:\n",
    "    if word.has_vector:\n",
    "        if word.is_lower:\n",
    "            if word.is_alpha:\n",
    "                sim = cosine_sim(new_vector,word.vector)\n",
    "                computed_sims.append((word,sim)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(<spacy.lexeme.Lexeme at 0x1f4adfed188>, -0.008464708924293518),\n",
       " (<spacy.lexeme.Lexeme at 0x1f4adfed458>, 0.07630855590105057)]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "computed_sims[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "computed_sims = sorted(computed_sims,key = lambda item: -item[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wolf',\n",
       " 'wolves',\n",
       " 'panther',\n",
       " 'lynx',\n",
       " 'owl',\n",
       " 'tiger',\n",
       " 'lion',\n",
       " 'fox',\n",
       " 'cat',\n",
       " 'otter']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w[0].text for w in computed_sims[:10]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challeng: Write a function that takes in 3 strings, perform a-b+c arithmetic, and returns a top ten result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_math(a,b,c):\n",
    "    \n",
    "    word1 = nlp.vocab[a].vector\n",
    "    word2 = nlp.vocab[b].vector\n",
    "    word3 = nlp.vocab[c].vector\n",
    "    \n",
    "    new_vector = word1 - word2 + word3\n",
    "    \n",
    "    computed_sims = []\n",
    "\n",
    "    for word in nlp.vocab:\n",
    "        if word.has_vector:\n",
    "            if word.is_lower:\n",
    "                if word.is_alpha:\n",
    "                    sim = cosine_sim(new_vector,word.vector)\n",
    "                    computed_sims.append((word,sim)) \n",
    "    \n",
    "    computed_sims = sorted(computed_sims,key = lambda item: -item[1])\n",
    "    \n",
    "    return [w[0].text for w in computed_sims[:10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The above function is best example how to build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['king', 'queen', 'prince', 'kings', 'princess', 'royal', 'throne', 'queens', 'monarch', 'kingdom']\n"
     ]
    }
   ],
   "source": [
    "# Test the function on known words\n",
    "\n",
    "print(vector_math('king','man','woman'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['wolf', 'wolves', 'panther', 'lynx', 'owl', 'tiger', 'lion', 'fox', 'cat', 'otter']\n"
     ]
    }
   ],
   "source": [
    "print(vector_math('wolf','dog','cat'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Perform VADER Sentiment Analysis on your own review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write Code that returns a set of SentimentintensityAnalyzer polarity scores based on your own written review**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Sentiment Intensity Analyzer and create an sid object\n",
    "\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "sid = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a review as one continuous string (multiple sentences are ok)\n",
    "\n",
    "review = 'This moview was absolutely awful. The WORST Movie I have ever seen!!!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.507, 'neu': 0.493, 'pos': 0.0, 'compound': -0.8825}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# obtain the sid scores for your review\n",
    "\n",
    "sid.polarity_scores(review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challeng: Write a function that takes in a review and returns a score of \"Positive\", \"Negative\", or \"Neutral\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def review_rating(string):\n",
    "    scores = sid.polarity_scores(string)\n",
    "    \n",
    "    if scores['compound'] == 0:\n",
    "        return \"Neutral\"\n",
    "    \n",
    "    elif scores['compound'] > 0:\n",
    "        return \"Positive\"\n",
    "    \n",
    "    else:\n",
    "        return \"Negative\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Negative'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_rating(review)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
