{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "<a href='http://www.pieriandata.com'> <img src='../Pierian_Data_Logo.png' /></a>\n",
    "___\n",
    "# Question and Answer Chat Bots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data\n",
    "\n",
    "We will be working with the Babi Data Set from Facebook Research.\n",
    "\n",
    "Full Details: https://research.fb.com/downloads/babi/\n",
    "\n",
    "- Jason Weston, Antoine Bordes, Sumit Chopra, Tomas Mikolov, Alexander M. Rush,\n",
    "  \"Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks\",\n",
    "  http://arxiv.org/abs/1502.05698\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"train_qa.txt\", \"rb\") as fp:   # Unpickling\n",
    "    train_data =  pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"test_qa.txt\", \"rb\") as fp:   # Unpickling\n",
    "    test_data =  pickle.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the Format of the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Mary',\n",
       "  'moved',\n",
       "  'to',\n",
       "  'the',\n",
       "  'bathroom',\n",
       "  '.',\n",
       "  'Sandra',\n",
       "  'journeyed',\n",
       "  'to',\n",
       "  'the',\n",
       "  'bedroom',\n",
       "  '.'],\n",
       " ['Is', 'Sandra', 'in', 'the', 'hallway', '?'],\n",
       " 'no')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mary moved to the bathroom . Sandra journeyed to the bedroom .'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(train_data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Is Sandra in the hallway ?'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(train_data[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'no'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## Setting up Vocabulary of All Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a set that holds the vocab words\n",
    "vocab = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = test_data + train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for story, question , answer in all_data:\n",
    "    # In case you don't know what a union of sets is:\n",
    "    # https://www.programiz.com/python-programming/methods/set/union\n",
    "    vocab = vocab.union(set(story))\n",
    "    vocab = vocab.union(set(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab.add('no')\n",
    "vocab.add('yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.',\n",
       " '?',\n",
       " 'Daniel',\n",
       " 'Is',\n",
       " 'John',\n",
       " 'Mary',\n",
       " 'Sandra',\n",
       " 'apple',\n",
       " 'back',\n",
       " 'bathroom',\n",
       " 'bedroom',\n",
       " 'discarded',\n",
       " 'down',\n",
       " 'dropped',\n",
       " 'football',\n",
       " 'garden',\n",
       " 'got',\n",
       " 'grabbed',\n",
       " 'hallway',\n",
       " 'in',\n",
       " 'journeyed',\n",
       " 'kitchen',\n",
       " 'left',\n",
       " 'milk',\n",
       " 'moved',\n",
       " 'no',\n",
       " 'office',\n",
       " 'picked',\n",
       " 'put',\n",
       " 'the',\n",
       " 'there',\n",
       " 'to',\n",
       " 'took',\n",
       " 'travelled',\n",
       " 'up',\n",
       " 'went',\n",
       " 'yes'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_len = len(vocab) + 1 #we add an extra space to hold a 0 for Keras's pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_story_len = max([len(data[0]) for data in all_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_story_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_question_len = max([len(data[1]) for data in all_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_question_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorizing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.',\n",
       " '?',\n",
       " 'Daniel',\n",
       " 'Is',\n",
       " 'John',\n",
       " 'Mary',\n",
       " 'Sandra',\n",
       " 'apple',\n",
       " 'back',\n",
       " 'bathroom',\n",
       " 'bedroom',\n",
       " 'discarded',\n",
       " 'down',\n",
       " 'dropped',\n",
       " 'football',\n",
       " 'garden',\n",
       " 'got',\n",
       " 'grabbed',\n",
       " 'hallway',\n",
       " 'in',\n",
       " 'journeyed',\n",
       " 'kitchen',\n",
       " 'left',\n",
       " 'milk',\n",
       " 'moved',\n",
       " 'no',\n",
       " 'office',\n",
       " 'picked',\n",
       " 'put',\n",
       " 'the',\n",
       " 'there',\n",
       " 'to',\n",
       " 'took',\n",
       " 'travelled',\n",
       " 'up',\n",
       " 'went',\n",
       " 'yes'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reserve 0 for pad_sequences\n",
    "vocab_size = len(vocab) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# integer encode sequences of words\n",
    "tokenizer = Tokenizer(filters=[])\n",
    "tokenizer.fit_on_texts(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'got': 1,\n",
       " 'put': 2,\n",
       " 'took': 3,\n",
       " 'back': 4,\n",
       " 'yes': 5,\n",
       " 'john': 6,\n",
       " '.': 7,\n",
       " 'mary': 8,\n",
       " 'kitchen': 9,\n",
       " 'in': 10,\n",
       " 'the': 11,\n",
       " 'down': 12,\n",
       " 'daniel': 13,\n",
       " 'moved': 14,\n",
       " 'travelled': 15,\n",
       " 'bedroom': 16,\n",
       " 'went': 17,\n",
       " 'there': 18,\n",
       " 'apple': 19,\n",
       " 'left': 20,\n",
       " 'garden': 21,\n",
       " 'milk': 22,\n",
       " 'dropped': 23,\n",
       " 'picked': 24,\n",
       " 'no': 25,\n",
       " '?': 26,\n",
       " 'discarded': 27,\n",
       " 'grabbed': 28,\n",
       " 'is': 29,\n",
       " 'football': 30,\n",
       " 'hallway': 31,\n",
       " 'up': 32,\n",
       " 'to': 33,\n",
       " 'bathroom': 34,\n",
       " 'office': 35,\n",
       " 'journeyed': 36,\n",
       " 'sandra': 37}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_story_text = []\n",
    "train_question_text = []\n",
    "train_answers = []\n",
    "\n",
    "for story,question,answer in train_data:\n",
    "    train_story_text.append(story)\n",
    "    train_question_text.append(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_story_seq = tokenizer.texts_to_sequences(train_story_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_story_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_story_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functionalize Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_stories(data, word_index=tokenizer.word_index, max_story_len=max_story_len,max_question_len=max_question_len):\n",
    "    '''\n",
    "    INPUT: \n",
    "    \n",
    "    data: consisting of Stories,Queries,and Answers\n",
    "    word_index: word index dictionary from tokenizer\n",
    "    max_story_len: the length of the longest story (used for pad_sequences function)\n",
    "    max_question_len: length of the longest question (used for pad_sequences function)\n",
    "\n",
    "\n",
    "    OUTPUT:\n",
    "    \n",
    "    Vectorizes the stories,questions, and answers into padded sequences. We first loop for every story, query , and\n",
    "    answer in the data. Then we convert the raw words to an word index value. Then we append each set to their appropriate\n",
    "    output list. Then once we have converted the words to numbers, we pad the sequences so they are all of equal length.\n",
    "    \n",
    "    Returns this in the form of a tuple (X,Xq,Y) (padded based on max lengths)\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    # X = STORIES\n",
    "    X = []\n",
    "    # Xq = QUERY/QUESTION\n",
    "    Xq = []\n",
    "    # Y = CORRECT ANSWER\n",
    "    Y = []\n",
    "    \n",
    "    \n",
    "    for story, query, answer in data:\n",
    "        \n",
    "        # Grab the word index for every word in story\n",
    "        x = [word_index[word.lower()] for word in story]\n",
    "        # Grab the word index for every word in query\n",
    "        xq = [word_index[word.lower()] for word in query]\n",
    "        \n",
    "        # Grab the Answers (either Yes/No so we don't need to use list comprehension here)\n",
    "        # Index 0 is reserved so we're going to use + 1\n",
    "        y = np.zeros(len(word_index) + 1)\n",
    "        \n",
    "        # Now that y is all zeros and we know its just Yes/No , we can use numpy logic to create this assignment\n",
    "        #\n",
    "        y[word_index[answer]] = 1\n",
    "        \n",
    "        # Append each set of story,query, and answer to their respective holding lists\n",
    "        X.append(x)\n",
    "        Xq.append(xq)\n",
    "        Y.append(y)\n",
    "        \n",
    "    # Finally, pad the sequences based on their max length so the RNN can be trained on uniformly long sequences.\n",
    "        \n",
    "    # RETURN TUPLE FOR UNPACKING\n",
    "    return (pad_sequences(X, maxlen=max_story_len),pad_sequences(Xq, maxlen=max_question_len), np.array(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_train, queries_train, answers_train = vectorize_stories(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_test, queries_test, answers_test = vectorize_stories(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0, ..., 11, 16,  7],\n",
       "       [ 0,  0,  0, ..., 11, 21,  7],\n",
       "       [ 0,  0,  0, ..., 11, 21,  7],\n",
       "       ...,\n",
       "       [ 0,  0,  0, ..., 11, 19,  7],\n",
       "       [ 0,  0,  0, ..., 11, 21,  7],\n",
       "       [ 0,  0,  0, ..., 19, 18,  7]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[29,  6, 10, 11,  9, 26],\n",
       "       [29,  6, 10, 11,  9, 26],\n",
       "       [29,  6, 10, 11, 21, 26],\n",
       "       ...,\n",
       "       [29,  8, 10, 11, 16, 26],\n",
       "       [29, 37, 10, 11, 21, 26],\n",
       "       [29,  8, 10, 11, 21, 26]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.,   0.,   0.,   0.,   0., 497.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0., 503.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(answers_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index['yes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index['no']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import Input, Activation, Dense, Permute, Dropout\n",
    "from keras.layers import add, dot, concatenate\n",
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Placeholders for Inputs\n",
    "\n",
    "Recall we technically have two inputs, stories and questions. So we need to use placeholders. `Input()` is used to instantiate a Keras tensor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequence = Input((max_story_len,))\n",
    "question = Input((max_question_len,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Building the Networks\n",
    "\n",
    "To understand why we chose this setup, make sure to read the paper we are using:\n",
    "\n",
    "* Sainbayar Sukhbaatar, Arthur Szlam, Jason Weston, Rob Fergus,\n",
    "  \"End-To-End Memory Networks\",\n",
    "  http://arxiv.org/abs/1503.08895"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoders\n",
    "\n",
    "### Input Encoder m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input gets embedded to a sequence of vectors\n",
    "input_encoder_m = Sequential()\n",
    "input_encoder_m.add(Embedding(input_dim=vocab_size,output_dim=64))\n",
    "input_encoder_m.add(Dropout(0.3))\n",
    "\n",
    "# This encoder will output:\n",
    "# (samples, story_maxlen, embedding_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Encoder c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embed the input into a sequence of vectors of size query_maxlen\n",
    "input_encoder_c = Sequential()\n",
    "input_encoder_c.add(Embedding(input_dim=vocab_size,output_dim=max_question_len))\n",
    "input_encoder_c.add(Dropout(0.3))\n",
    "# output: (samples, story_maxlen, query_maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embed the question into a sequence of vectors\n",
    "question_encoder = Sequential()\n",
    "question_encoder.add(Embedding(input_dim=vocab_size,\n",
    "                               output_dim=64,\n",
    "                               input_length=max_question_len))\n",
    "question_encoder.add(Dropout(0.3))\n",
    "# output: (samples, query_maxlen, embedding_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode the Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode input sequence and questions (which are indices)\n",
    "# to sequences of dense vectors\n",
    "input_encoded_m = input_encoder_m(input_sequence)\n",
    "input_encoded_c = input_encoder_c(input_sequence)\n",
    "question_encoded = question_encoder(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Use dot product to compute the match between first input vector seq and the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape: `(samples, story_maxlen, query_maxlen)`\n",
    "match = dot([input_encoded_m, question_encoded], axes=(2, 2))\n",
    "match = Activation('softmax')(match)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add this match matrix with the second input vector sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the match matrix with the second input vector sequence\n",
    "response = add([match, input_encoded_c])  # (samples, story_maxlen, query_maxlen)\n",
    "response = Permute((2, 1))(response)  # (samples, query_maxlen, story_maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate the match matrix with the question vector sequence\n",
    "answer = concatenate([response, question_encoded])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'concatenate/Identity:0' shape=(None, 6, 220) dtype=float32>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce with RNN (LSTM)\n",
    "answer = LSTM(32)(answer)  # (samples, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regularization with Dropout\n",
    "answer = Dropout(0.5)(answer)\n",
    "answer = Dense(vocab_size)(answer)  # (samples, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we output a probability distribution over the vocabulary\n",
    "answer = Activation('softmax')(answer)\n",
    "\n",
    "# build the final model\n",
    "model = Model([input_sequence, question], answer)\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 156)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 6)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential (Sequential)         multiple             2432        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sequential_2 (Sequential)       (None, 6, 64)        2432        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot (Dot)                       (None, 156, 6)       0           sequential[1][0]                 \n",
      "                                                                 sequential_2[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 156, 6)       0           dot[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       multiple             228         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 156, 6)       0           activation[0][0]                 \n",
      "                                                                 sequential_1[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "permute (Permute)               (None, 6, 156)       0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 6, 220)       0           permute[0][0]                    \n",
      "                                                                 sequential_2[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 32)           32384       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 32)           0           lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 38)           1254        dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 38)           0           dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 38,730\n",
      "Trainable params: 38,730\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000012A8704CB88> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000012A8704CB88> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "309/313 [============================>.] - ETA: 0s - loss: 0.9100 - accuracy: 0.4826WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000012A9E727C18> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000012A9E727C18> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "313/313 [==============================] - 3s 10ms/step - loss: 0.9079 - accuracy: 0.4819 - val_loss: 0.6946 - val_accuracy: 0.4970\n",
      "Epoch 2/120\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.7004 - accuracy: 0.5003 - val_loss: 0.6960 - val_accuracy: 0.5030\n",
      "Epoch 3/120\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.6952 - accuracy: 0.5086 - val_loss: 0.6962 - val_accuracy: 0.5030\n",
      "Epoch 4/120\n",
      "313/313 [==============================] - 4s 11ms/step - loss: 0.6950 - accuracy: 0.5047 - val_loss: 0.6933 - val_accuracy: 0.5030\n",
      "Epoch 5/120\n",
      "313/313 [==============================] - 3s 11ms/step - loss: 0.6945 - accuracy: 0.4992 - val_loss: 0.6936 - val_accuracy: 0.4970\n",
      "Epoch 6/120\n",
      "313/313 [==============================] - 3s 10ms/step - loss: 0.6948 - accuracy: 0.4975 - val_loss: 0.6932 - val_accuracy: 0.5030\n",
      "Epoch 7/120\n",
      "313/313 [==============================] - 3s 10ms/step - loss: 0.6939 - accuracy: 0.5082 - val_loss: 0.6933 - val_accuracy: 0.5030\n",
      "Epoch 8/120\n",
      "313/313 [==============================] - 4s 11ms/step - loss: 0.6942 - accuracy: 0.5055 - val_loss: 0.6942 - val_accuracy: 0.5050\n",
      "Epoch 9/120\n",
      "313/313 [==============================] - 3s 10ms/step - loss: 0.6933 - accuracy: 0.5107 - val_loss: 0.6937 - val_accuracy: 0.4940\n",
      "Epoch 10/120\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.6908 - accuracy: 0.5181 - val_loss: 0.6906 - val_accuracy: 0.4830\n",
      "Epoch 11/120\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.6822 - accuracy: 0.5486 - val_loss: 0.6773 - val_accuracy: 0.5980\n",
      "Epoch 12/120\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.6714 - accuracy: 0.5891 - val_loss: 0.6524 - val_accuracy: 0.6320\n",
      "Epoch 13/120\n",
      "313/313 [==============================] - 3s 11ms/step - loss: 0.6482 - accuracy: 0.6340 - val_loss: 0.6353 - val_accuracy: 0.6530\n",
      "Epoch 14/120\n",
      "313/313 [==============================] - 4s 11ms/step - loss: 0.6339 - accuracy: 0.6492 - val_loss: 0.6243 - val_accuracy: 0.6520\n",
      "Epoch 15/120\n",
      "313/313 [==============================] - 3s 11ms/step - loss: 0.6241 - accuracy: 0.6616 - val_loss: 0.6203 - val_accuracy: 0.6590\n",
      "Epoch 16/120\n",
      "313/313 [==============================] - 3s 11ms/step - loss: 0.6142 - accuracy: 0.6699 - val_loss: 0.5977 - val_accuracy: 0.6850\n",
      "Epoch 17/120\n",
      "313/313 [==============================] - 3s 11ms/step - loss: 0.5864 - accuracy: 0.6970 - val_loss: 0.5449 - val_accuracy: 0.7330\n",
      "Epoch 18/120\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.5530 - accuracy: 0.7206 - val_loss: 0.5256 - val_accuracy: 0.7490\n",
      "Epoch 19/120\n",
      "313/313 [==============================] - 3s 11ms/step - loss: 0.5271 - accuracy: 0.7372 - val_loss: 0.5156 - val_accuracy: 0.7560\n",
      "Epoch 20/120\n",
      "313/313 [==============================] - 4s 11ms/step - loss: 0.5037 - accuracy: 0.7623 - val_loss: 0.4876 - val_accuracy: 0.7760\n",
      "Epoch 21/120\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.4837 - accuracy: 0.7747 - val_loss: 0.4557 - val_accuracy: 0.7970\n",
      "Epoch 22/120\n",
      "313/313 [==============================] - 3s 11ms/step - loss: 0.4575 - accuracy: 0.7944 - val_loss: 0.4375 - val_accuracy: 0.8030\n",
      "Epoch 23/120\n",
      "313/313 [==============================] - 3s 11ms/step - loss: 0.4382 - accuracy: 0.8047 - val_loss: 0.4249 - val_accuracy: 0.8060\n",
      "Epoch 24/120\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.4212 - accuracy: 0.8209 - val_loss: 0.4109 - val_accuracy: 0.8150\n",
      "Epoch 25/120\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.4083 - accuracy: 0.8226 - val_loss: 0.4011 - val_accuracy: 0.8280\n",
      "Epoch 26/120\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 0.3891 - accuracy: 0.8305 - val_loss: 0.4259 - val_accuracy: 0.8280\n",
      "Epoch 27/120\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.3887 - accuracy: 0.8360 - val_loss: 0.3991 - val_accuracy: 0.8180\n",
      "Epoch 28/120\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.3785 - accuracy: 0.8416 - val_loss: 0.3914 - val_accuracy: 0.8240\n",
      "Epoch 29/120\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.3732 - accuracy: 0.8410 - val_loss: 0.4018 - val_accuracy: 0.8190\n",
      "Epoch 30/120\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.3710 - accuracy: 0.8430 - val_loss: 0.4138 - val_accuracy: 0.8290\n",
      "Epoch 31/120\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 0.3616 - accuracy: 0.8478 - val_loss: 0.4076 - val_accuracy: 0.8180\n",
      "Epoch 32/120\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.3583 - accuracy: 0.8523 - val_loss: 0.3881 - val_accuracy: 0.8290\n",
      "Epoch 33/120\n",
      "313/313 [==============================] - 3s 11ms/step - loss: 0.3551 - accuracy: 0.8490 - val_loss: 0.3869 - val_accuracy: 0.8220\n",
      "Epoch 34/120\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.3516 - accuracy: 0.8571 - val_loss: 0.3813 - val_accuracy: 0.8150\n",
      "Epoch 35/120\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.3454 - accuracy: 0.8541 - val_loss: 0.3827 - val_accuracy: 0.8300\n",
      "Epoch 36/120\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.3379 - accuracy: 0.8562 - val_loss: 0.3822 - val_accuracy: 0.8260\n",
      "Epoch 37/120\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.3415 - accuracy: 0.8595 - val_loss: 0.3761 - val_accuracy: 0.8290\n",
      "Epoch 38/120\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.3389 - accuracy: 0.8570 - val_loss: 0.3772 - val_accuracy: 0.8300\n",
      "Epoch 39/120\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.3282 - accuracy: 0.8631 - val_loss: 0.3800 - val_accuracy: 0.8330\n",
      "Epoch 40/120\n",
      "313/313 [==============================] - 4s 11ms/step - loss: 0.3338 - accuracy: 0.8595 - val_loss: 0.3853 - val_accuracy: 0.8260\n",
      "Epoch 41/120\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.3258 - accuracy: 0.8607 - val_loss: 0.3811 - val_accuracy: 0.8300\n",
      "Epoch 42/120\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.3309 - accuracy: 0.8608 - val_loss: 0.3824 - val_accuracy: 0.8290\n",
      "Epoch 43/120\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.3250 - accuracy: 0.8633 - val_loss: 0.3864 - val_accuracy: 0.8320\n",
      "Epoch 44/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 4s 12ms/step - loss: 0.3249 - accuracy: 0.8659 - val_loss: 0.3855 - val_accuracy: 0.8300\n",
      "Epoch 45/120\n",
      "313/313 [==============================] - 4s 11ms/step - loss: 0.3192 - accuracy: 0.8681 - val_loss: 0.3806 - val_accuracy: 0.8300\n",
      "Epoch 46/120\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.3189 - accuracy: 0.8643 - val_loss: 0.3756 - val_accuracy: 0.8270\n",
      "Epoch 47/120\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.3145 - accuracy: 0.8686 - val_loss: 0.3841 - val_accuracy: 0.8310\n",
      "Epoch 48/120\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.3136 - accuracy: 0.8693 - val_loss: 0.4003 - val_accuracy: 0.8200\n",
      "Epoch 49/120\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.3079 - accuracy: 0.8677 - val_loss: 0.3894 - val_accuracy: 0.8160\n",
      "Epoch 50/120\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.3116 - accuracy: 0.8698 - val_loss: 0.3933 - val_accuracy: 0.8240\n",
      "Epoch 51/120\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.3036 - accuracy: 0.8699 - val_loss: 0.3949 - val_accuracy: 0.8340\n",
      "Epoch 52/120\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.3035 - accuracy: 0.8732 - val_loss: 0.3894 - val_accuracy: 0.8330\n",
      "Epoch 53/120\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.3004 - accuracy: 0.8746 - val_loss: 0.4047 - val_accuracy: 0.8230 0s - loss: 0.3003 - accuracy: 0.87\n",
      "Epoch 54/120\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.3038 - accuracy: 0.8735 - val_loss: 0.3932 - val_accuracy: 0.8220\n",
      "Epoch 55/120\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.3023 - accuracy: 0.8740 - val_loss: 0.4005 - val_accuracy: 0.8330\n",
      "Epoch 56/120\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.2951 - accuracy: 0.8759 - val_loss: 0.3881 - val_accuracy: 0.8240\n",
      "Epoch 57/120\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.2985 - accuracy: 0.8739 - val_loss: 0.3979 - val_accuracy: 0.8300\n",
      "Epoch 58/120\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.2987 - accuracy: 0.8711 - val_loss: 0.4139 - val_accuracy: 0.8070\n",
      "Epoch 59/120\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.2924 - accuracy: 0.8789 - val_loss: 0.4122 - val_accuracy: 0.8250\n",
      "Epoch 60/120\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.2833 - accuracy: 0.8822 - val_loss: 0.4222 - val_accuracy: 0.8280\n",
      "Epoch 61/120\n",
      "313/313 [==============================] - 3s 11ms/step - loss: 0.2938 - accuracy: 0.8755 - val_loss: 0.4251 - val_accuracy: 0.8310\n",
      "Epoch 62/120\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.2912 - accuracy: 0.8764 - val_loss: 0.4262 - val_accuracy: 0.8290\n",
      "Epoch 63/120\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.2884 - accuracy: 0.8810 - val_loss: 0.4165 - val_accuracy: 0.8210\n",
      "Epoch 64/120\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.2869 - accuracy: 0.8800 - val_loss: 0.4173 - val_accuracy: 0.8290\n",
      "Epoch 65/120\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.2797 - accuracy: 0.8817 - val_loss: 0.4080 - val_accuracy: 0.8310\n",
      "Epoch 66/120\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.2802 - accuracy: 0.8812 - val_loss: 0.4102 - val_accuracy: 0.8280\n",
      "Epoch 67/120\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.2753 - accuracy: 0.8852 - val_loss: 0.4387 - val_accuracy: 0.8190\n",
      "Epoch 68/120\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.2817 - accuracy: 0.8826 - val_loss: 0.4197 - val_accuracy: 0.8240\n",
      "Epoch 69/120\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.2768 - accuracy: 0.8839 - val_loss: 0.4515 - val_accuracy: 0.8160\n",
      "Epoch 70/120\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.2704 - accuracy: 0.8882 - val_loss: 0.4305 - val_accuracy: 0.8290\n",
      "Epoch 71/120\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.2694 - accuracy: 0.8903 - val_loss: 0.4206 - val_accuracy: 0.8150\n",
      "Epoch 72/120\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.2743 - accuracy: 0.8854 - val_loss: 0.4601 - val_accuracy: 0.8220\n",
      "Epoch 73/120\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.2693 - accuracy: 0.8881 - val_loss: 0.4165 - val_accuracy: 0.8170\n",
      "Epoch 74/120\n",
      "313/313 [==============================] - 3s 11ms/step - loss: 0.2729 - accuracy: 0.8857 - val_loss: 0.4488 - val_accuracy: 0.8100\n",
      "Epoch 75/120\n",
      "313/313 [==============================] - 3s 11ms/step - loss: 0.2715 - accuracy: 0.8861 - val_loss: 0.4375 - val_accuracy: 0.8180\n",
      "Epoch 76/120\n",
      "313/313 [==============================] - 3s 11ms/step - loss: 0.2688 - accuracy: 0.8901 - val_loss: 0.4481 - val_accuracy: 0.8260\n",
      "Epoch 77/120\n",
      "313/313 [==============================] - 3s 11ms/step - loss: 0.2647 - accuracy: 0.8899 - val_loss: 0.4441 - val_accuracy: 0.8140\n",
      "Epoch 78/120\n",
      "313/313 [==============================] - 4s 11ms/step - loss: 0.2557 - accuracy: 0.8910 - val_loss: 0.4421 - val_accuracy: 0.8130\n",
      "Epoch 79/120\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.2640 - accuracy: 0.8913 - val_loss: 0.4555 - val_accuracy: 0.8090\n",
      "Epoch 80/120\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.2626 - accuracy: 0.8870 - val_loss: 0.4536 - val_accuracy: 0.8210\n",
      "Epoch 81/120\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 0.2561 - accuracy: 0.8924 - val_loss: 0.4605 - val_accuracy: 0.8160\n",
      "Epoch 82/120\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.2567 - accuracy: 0.8925 - val_loss: 0.4355 - val_accuracy: 0.8230\n",
      "Epoch 83/120\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.2529 - accuracy: 0.8955 - val_loss: 0.4768 - val_accuracy: 0.8160\n",
      "Epoch 84/120\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 0.2513 - accuracy: 0.8949 - val_loss: 0.4791 - val_accuracy: 0.8170\n",
      "Epoch 85/120\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.2509 - accuracy: 0.8967 - val_loss: 0.4965 - val_accuracy: 0.8190\n",
      "Epoch 86/120\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.2489 - accuracy: 0.8977 - val_loss: 0.4632 - val_accuracy: 0.8020\n",
      "Epoch 87/120\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 0.2513 - accuracy: 0.8957 - val_loss: 0.4770 - val_accuracy: 0.8290\n",
      "Epoch 88/120\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.2504 - accuracy: 0.8972 - val_loss: 0.4488 - val_accuracy: 0.8150\n",
      "Epoch 89/120\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.2466 - accuracy: 0.9005 - val_loss: 0.4638 - val_accuracy: 0.8230\n",
      "Epoch 90/120\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.2483 - accuracy: 0.8994 - val_loss: 0.4707 - val_accuracy: 0.8220\n",
      "Epoch 91/120\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.2422 - accuracy: 0.9007 - val_loss: 0.4755 - val_accuracy: 0.8150\n",
      "Epoch 92/120\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.2433 - accuracy: 0.8989 - val_loss: 0.5042 - val_accuracy: 0.8130\n",
      "Epoch 93/120\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.2425 - accuracy: 0.8982 - val_loss: 0.4804 - val_accuracy: 0.8170\n",
      "Epoch 94/120\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.2322 - accuracy: 0.9041 - val_loss: 0.5228 - val_accuracy: 0.8090\n",
      "Epoch 95/120\n",
      "313/313 [==============================] - 4s 11ms/step - loss: 0.2379 - accuracy: 0.9025 - val_loss: 0.4716 - val_accuracy: 0.8190\n",
      "Epoch 96/120\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.2423 - accuracy: 0.9015 - val_loss: 0.5051 - val_accuracy: 0.8060\n",
      "Epoch 97/120\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.2377 - accuracy: 0.9016 - val_loss: 0.4937 - val_accuracy: 0.8150\n",
      "Epoch 98/120\n",
      "313/313 [==============================] - 5s 14ms/step - loss: 0.2334 - accuracy: 0.9009 - val_loss: 0.5231 - val_accuracy: 0.8220\n",
      "Epoch 99/120\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.2371 - accuracy: 0.9039 - val_loss: 0.5329 - val_accuracy: 0.8120\n",
      "Epoch 100/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 4s 13ms/step - loss: 0.2322 - accuracy: 0.9064 - val_loss: 0.5302 - val_accuracy: 0.8170\n",
      "Epoch 101/120\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 0.2329 - accuracy: 0.9025 - val_loss: 0.5215 - val_accuracy: 0.8190\n",
      "Epoch 102/120\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.2285 - accuracy: 0.90 - 4s 12ms/step - loss: 0.2285 - accuracy: 0.9053 - val_loss: 0.5243 - val_accuracy: 0.8220\n",
      "Epoch 103/120\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.2257 - accuracy: 0.9079 - val_loss: 0.5317 - val_accuracy: 0.8220\n",
      "Epoch 104/120\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.2245 - accuracy: 0.9054 - val_loss: 0.5661 - val_accuracy: 0.8180\n",
      "Epoch 105/120\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.2239 - accuracy: 0.9059 - val_loss: 0.5487 - val_accuracy: 0.8180\n",
      "Epoch 106/120\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.2258 - accuracy: 0.9067 - val_loss: 0.5152 - val_accuracy: 0.8200\n",
      "Epoch 107/120\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 0.2227 - accuracy: 0.9084 - val_loss: 0.4922 - val_accuracy: 0.8240\n",
      "Epoch 108/120\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.2274 - accuracy: 0.9068 - val_loss: 0.5311 - val_accuracy: 0.8110\n",
      "Epoch 109/120\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.2221 - accuracy: 0.9093 - val_loss: 0.5384 - val_accuracy: 0.8090\n",
      "Epoch 110/120\n",
      "313/313 [==============================] - 3s 11ms/step - loss: 0.2185 - accuracy: 0.9123 - val_loss: 0.5411 - val_accuracy: 0.8160\n",
      "Epoch 111/120\n",
      "313/313 [==============================] - 3s 11ms/step - loss: 0.2230 - accuracy: 0.9097 - val_loss: 0.5409 - val_accuracy: 0.8150\n",
      "Epoch 112/120\n",
      "313/313 [==============================] - 3s 11ms/step - loss: 0.2238 - accuracy: 0.9092 - val_loss: 0.5621 - val_accuracy: 0.8180\n",
      "Epoch 113/120\n",
      "313/313 [==============================] - 3s 11ms/step - loss: 0.2210 - accuracy: 0.9101 - val_loss: 0.5645 - val_accuracy: 0.8200\n",
      "Epoch 114/120\n",
      "313/313 [==============================] - 3s 11ms/step - loss: 0.2122 - accuracy: 0.9157 - val_loss: 0.5660 - val_accuracy: 0.8120\n",
      "Epoch 115/120\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.2195 - accuracy: 0.9129 - val_loss: 0.5328 - val_accuracy: 0.8150\n",
      "Epoch 116/120\n",
      "313/313 [==============================] - 4s 11ms/step - loss: 0.2097 - accuracy: 0.9151 - val_loss: 0.5309 - val_accuracy: 0.8130\n",
      "Epoch 117/120\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.2128 - accuracy: 0.9125 - val_loss: 0.5590 - val_accuracy: 0.8080\n",
      "Epoch 118/120\n",
      "313/313 [==============================] - 4s 11ms/step - loss: 0.2103 - accuracy: 0.9155 - val_loss: 0.5693 - val_accuracy: 0.8030\n",
      "Epoch 119/120\n",
      "313/313 [==============================] - 3s 11ms/step - loss: 0.2073 - accuracy: 0.9171 - val_loss: 0.5941 - val_accuracy: 0.8080\n",
      "Epoch 120/120\n",
      "313/313 [==============================] - 4s 11ms/step - loss: 0.2146 - accuracy: 0.9143 - val_loss: 0.5725 - val_accuracy: 0.8200\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "history = model.fit([inputs_train, queries_train], answers_train,batch_size=32,epochs=120,validation_data=([inputs_test, queries_test], answers_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'chatbot_120_epochs.h5'\n",
    "model.save(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the Model\n",
    "\n",
    "### Plotting Out Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "#plt.plot(history.history['acc'])\n",
    "#plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating on Given Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x0000012AA3272A68> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x0000012AA3272A68> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Bad argument number for Name: 4, expecting 3\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "model.load_weights(filename)\n",
    "pred_results = model.predict(([inputs_test, queries_test]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mary',\n",
       " 'got',\n",
       " 'the',\n",
       " 'milk',\n",
       " 'there',\n",
       " '.',\n",
       " 'John',\n",
       " 'moved',\n",
       " 'to',\n",
       " 'the',\n",
       " 'bedroom',\n",
       " '.']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mary got the milk there . John moved to the bedroom .\n"
     ]
    }
   ],
   "source": [
    "story =' '.join(word for word in test_data[0][0])\n",
    "print(story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is John in the kitchen ?\n"
     ]
    }
   ],
   "source": [
    "query = ' '.join(word for word in test_data[0][1])\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Test Answer from Data is: no\n"
     ]
    }
   ],
   "source": [
    "print(\"True Test Answer from Data is:\",test_data[0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted answer is:  no\n",
      "Probability of certainty was:  0.9999536\n"
     ]
    }
   ],
   "source": [
    "#Generate prediction from model\n",
    "val_max = np.argmax(pred_results[0])\n",
    "\n",
    "for key, val in tokenizer.word_index.items():\n",
    "    if val == val_max:\n",
    "        k = key\n",
    "\n",
    "print(\"Predicted answer is: \", k)\n",
    "print(\"Probability of certainty was: \", pred_results[0][val_max])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing Your Own Stories and Questions\n",
    "\n",
    "Remember you can only use words from the existing vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.',\n",
       " '?',\n",
       " 'Daniel',\n",
       " 'Is',\n",
       " 'John',\n",
       " 'Mary',\n",
       " 'Sandra',\n",
       " 'apple',\n",
       " 'back',\n",
       " 'bathroom',\n",
       " 'bedroom',\n",
       " 'discarded',\n",
       " 'down',\n",
       " 'dropped',\n",
       " 'football',\n",
       " 'garden',\n",
       " 'got',\n",
       " 'grabbed',\n",
       " 'hallway',\n",
       " 'in',\n",
       " 'journeyed',\n",
       " 'kitchen',\n",
       " 'left',\n",
       " 'milk',\n",
       " 'moved',\n",
       " 'no',\n",
       " 'office',\n",
       " 'picked',\n",
       " 'put',\n",
       " 'the',\n",
       " 'there',\n",
       " 'to',\n",
       " 'took',\n",
       " 'travelled',\n",
       " 'up',\n",
       " 'went',\n",
       " 'yes'}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['John',\n",
       " 'left',\n",
       " 'the',\n",
       " 'kitchen',\n",
       " '.',\n",
       " 'Sandra',\n",
       " 'dropped',\n",
       " 'the',\n",
       " 'football',\n",
       " 'in',\n",
       " 'the',\n",
       " 'garden',\n",
       " '.']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note the whitespace of the periods\n",
    "my_story = \"John left the kitchen . Sandra dropped the football in the garden .\"\n",
    "my_story.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_question = \"Is the football in the garden ?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Is', 'the', 'football', 'in', 'the', 'garden', '?']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_question.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata = [(my_story.split(),my_question.split(),'yes')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_story,my_ques,my_ans = vectorize_stories(mydata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_results = model.predict(([ my_story, my_ques]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted answer is:  yes\n",
      "Probability of certainty was:  0.80170435\n"
     ]
    }
   ],
   "source": [
    "#Generate prediction from model\n",
    "val_max = np.argmax(pred_results[0])\n",
    "\n",
    "for key, val in tokenizer.word_index.items():\n",
    "    if val == val_max:\n",
    "        k = key\n",
    "\n",
    "print(\"Predicted answer is: \", k)\n",
    "print(\"Probability of certainty was: \", pred_results[0][val_max])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Great Job!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
